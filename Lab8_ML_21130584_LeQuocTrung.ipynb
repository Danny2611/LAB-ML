{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Danny2611/LAB-ML/blob/master/Lab8_ML_21130584_LeQuocTrung.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMzehe0sy5wr"
      },
      "source": [
        "The main aim of this lab is to deal with the **pipeline** technique and **MultilayerPerceptron** algorithm\n",
        "\n",
        "*   **Deadline: 23:59, 06/5/2024**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4nJmxp9zGX4"
      },
      "source": [
        "# Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DoVWQ8AEyc-C",
        "outputId": "6e5af972-553e-4909-fb19-b57cfb546944"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ]
        }
      ],
      "source": [
        "# code\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.datasets import load_iris, load_breast_cancer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_selection import RFE, SelectKBest, chi2\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
        "from sklearn.naive_bayes import CategoricalNB, GaussianNB, BernoulliNB, MultinomialNB, ComplementNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder, KBinsDiscretizer, OneHotEncoder\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import KBinsDiscretizer, StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "from prettytable import PrettyTable\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "%pylab inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_dG9SA5OhGT"
      },
      "source": [
        "#Task 1. With **iris** dataset\n",
        "*  Apply **pipeline** including preprocessing steps (i.e., **StandardScaler**, **SimpleImputer**, **feature selection**, **KBinsDiscretizer**, …) and classification algorithms (i.e., **Random forest, kNN, Naïve Bayes**).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62jExOZ952fF",
        "outputId": "5579c437-dbd5-429d-df04-40971f92d838"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     Classifier                                Preprocessing Steps  Accuracy  \\\n",
            "0  RandomForest  [(scaler, StandardScaler()), (imputer, SimpleI...  0.973333   \n",
            "1           kNN  [(scaler, StandardScaler()), (imputer, SimpleI...  0.960000   \n",
            "2    NaiveBayes  [(scaler, StandardScaler()), (imputer, SimpleI...  0.966667   \n",
            "\n",
            "   Precision    Recall  F1_Score  \n",
            "0   0.973825  0.973333  0.973323  \n",
            "1   0.960000  0.960000  0.960000  \n",
            "2   0.966787  0.966667  0.966663  \n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "\n",
        "models = {\n",
        "    'RandomForest': RandomForestClassifier(),\n",
        "    'kNN': KNeighborsClassifier(),\n",
        "    'NaiveBayes': GaussianNB()\n",
        "}\n",
        "\n",
        "preprocessing = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('imputer', SimpleImputer(strategy='mean')),\n",
        "    ('feature_selection', SelectKBest(k=4)),\n",
        "    ('discretizer', KBinsDiscretizer(n_bins=3, encode='ordinal', strategy='uniform')),\n",
        "    ('pca', PCA(n_components=2))\n",
        "])\n",
        "\n",
        "\n",
        "result_pipelines = my_pipeline(X, y, preprocessing, models)\n",
        "\n",
        "\n",
        "results = []\n",
        "\n",
        "for model_name, pipeline in result_pipelines.items():\n",
        "    y_pred = pipeline.predict(X)\n",
        "    accuracy = accuracy_score(y, y_pred)\n",
        "    precision = precision_score(y, y_pred, average='weighted')\n",
        "    recall = recall_score(y, y_pred, average='weighted')\n",
        "    f1 = f1_score(y, y_pred, average='weighted')\n",
        "    results.append([model_name, preprocessing.steps, accuracy, precision, recall, f1])\n",
        "\n",
        "\n",
        "results_df = pd.DataFrame(results, columns=[\"Classifier\", \"Preprocessing Steps\", \"Accuracy\", \"Precision\", \"Recall\", \"F1_Score\"])\n",
        "\n",
        "\n",
        "print(results_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNv07ARGzOUm"
      },
      "source": [
        "#Task 2. With **fashion** dataset\n",
        "*   2.1. Apply **MultilayerPerceptron** classification with 1 hidden layer\n",
        "having 10 nodes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOsg77IBzEyo",
        "outputId": "0fbe88f5-708c-4a15-c1d8-2407606e3801"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------------------+--------------------+----------+---------------------+---------------------+---------------------+\n",
            "|       AlgoName       | Hidden layer sizes | Accuracy |      Precision      |        Recall       |       F1_Score      |\n",
            "+----------------------+--------------------+----------+---------------------+---------------------+---------------------+\n",
            "| MultilayerPerceptron |       (10,)        |  0.148   | 0.08899388048956083 | 0.16263736263736264 | 0.08783442218482124 |\n",
            "+----------------------+--------------------+----------+---------------------+---------------------+---------------------+\n"
          ]
        }
      ],
      "source": [
        "# code\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from prettytable import PrettyTable\n",
        "\n",
        "def my_MLPClassifier(X_train, X_test, y_train, y_test, hidden_layer_sizes):\n",
        "\n",
        "    clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=hidden_layer_sizes, random_state=1)\n",
        "\n",
        "\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "    y_pred = clf.predict(X_test)\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred, average='macro')\n",
        "    recall = recall_score(y_test, y_pred, average='macro')\n",
        "    f1 = f1_score(y_test, y_pred, average='macro')\n",
        "\n",
        "    table = PrettyTable([\"AlgoName\", \"Hidden layer sizes\", \"Accuracy\", \"Precision\", \"Recall\", \"F1_Score\"])\n",
        "    table.add_row(['MultilayerPerceptron', hidden_layer_sizes, accuracy, precision, recall, f1])\n",
        "\n",
        "    return table\n",
        "\n",
        "\n",
        "data_train = pd.read_csv('/content/sample_data/fashion_train.csv')\n",
        "data_test = pd.read_csv('/content/sample_data/fashion_test.csv')\n",
        "\n",
        "X_train = data_train.drop(columns=['y'])\n",
        "y_train = data_train['y']\n",
        "X_test = data_test.drop(columns=['y'])\n",
        "y_test = data_test['y']\n",
        "\n",
        "clf = my_MLPClassifier(X_train, X_test, y_train, y_test, (10,))\n",
        "print(clf)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnoVB8J4vV36"
      },
      "source": [
        "*   2.2. Apply **MultilayerPerceptron** algorithm with the following settings (the first hidden layer has 250 neuron, the second one has 100 neurons)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ZTSvsJdvYqI",
        "outputId": "a30f96de-7cda-4896-eaca-d3edf484f544"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------------------+--------------------+----------+--------------------+-------------------+--------------------+\n",
            "|       AlgoName       | Hidden layer sizes | Accuracy |     Precision      |       Recall      |      F1_Score      |\n",
            "+----------------------+--------------------+----------+--------------------+-------------------+--------------------+\n",
            "| MultilayerPerceptron |     (250, 100)     |  0.762   | 0.7600749070563724 | 0.759490035340887 | 0.7566185000787782 |\n",
            "+----------------------+--------------------+----------+--------------------+-------------------+--------------------+\n"
          ]
        }
      ],
      "source": [
        "# code\n",
        "clf = my_MLPClassifier(X_train, X_test, y_train, y_test, (250, 100))\n",
        "print(clf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyey-ndXvZlb"
      },
      "source": [
        "*   2.3. Find the best hyperparameters using **GridSearchCV**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Qzh_D-rgvbv9",
        "outputId": "c6a0282f-3b36-408c-9285-12ba2e6f213e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classifier: MLPClassifier, Params: {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (150, 100, 50), 'learning_rate': 'constant', 'max_iter': 50, 'solver': 'adam'}\n",
            "+------------------------------------------+----------+--------------------+--------------------+--------------------+\n",
            "| Classifier with the best hyperparameters | Accuracy |     Precision      |       Recall       |      F1_Score      |\n",
            "+------------------------------------------+----------+--------------------+--------------------+--------------------+\n",
            "|              MLPClassifier               |   0.69   | 0.6855555555555555 | 0.6552913752913753 | 0.6619396759051932 |\n",
            "+------------------------------------------+----------+--------------------+--------------------+--------------------+\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from prettytable import PrettyTable\n",
        "\n",
        "def myGridSearchCV(X_train, y_train, X_test, y_test, classifier, params):\n",
        "\n",
        "    grid_search = GridSearchCV(\n",
        "        estimator=classifier,\n",
        "        param_grid=params,\n",
        "        scoring='accuracy',\n",
        "        refit=True,\n",
        "        cv=10,\n",
        "        return_train_score=True,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "    y_pred = grid_search.predict(X_test)\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred, average='macro')\n",
        "    recall = recall_score(y_test, y_pred, average='macro')\n",
        "    f1 = f1_score(y_test, y_pred, average='macro')\n",
        "\n",
        "\n",
        "    algoName = classifier.__class__.__name__\n",
        "\n",
        "    best_params = grid_search.best_params_\n",
        "\n",
        "    return algoName, best_params, accuracy, precision, recall, f1\n",
        "\n",
        "\n",
        "data_train = pd.read_csv('/content/sample_data/fashion_train.csv', nrows=200)\n",
        "data_test = pd.read_csv('/content/sample_data/fashion_test.csv', nrows=100)\n",
        "\n",
        "\n",
        "X_train = data_train.drop(columns=['y'])\n",
        "y_train = data_train['y']\n",
        "X_test = data_test.drop(columns=['y'])\n",
        "y_test = data_test['y']\n",
        "\n",
        "\n",
        "param_grid = {\n",
        "    'hidden_layer_sizes': [(150, 100, 50), (120, 80, 40), (100, 50, 30)],\n",
        "    'max_iter': [50, 100, 150],\n",
        "    'activation': ['tanh', 'relu'],\n",
        "    'solver': ['sgd', 'adam'],\n",
        "    'alpha': [0.0001, 0.05],\n",
        "    'learning_rate': ['constant', 'adaptive'],\n",
        "}\n",
        "\n",
        "\n",
        "algoName, best_params, accuracy, precision, recall, f1 = myGridSearchCV(X_train, y_train, X_test, y_test, MLPClassifier(random_state=1), param_grid)\n",
        "\n",
        "print(f\"Classifier: {algoName}, Params: {best_params}\")\n",
        "\n",
        "table = PrettyTable([\"Classifier with the best hyperparameters\", \"Accuracy\", \"Precision\", \"Recall\", \"F1_Score\"])\n",
        "table.add_row([algoName, accuracy, precision, recall, f1])\n",
        "print(table)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ol1U_T_NvcqV"
      },
      "source": [
        "*   2.4. Compare the **MultilayerPerceptron** using the best hyperparameters in 2.3 and other classification algorithms (i.e., Random forest, kNN, Naïve Bayes)  in termns of accuracy, precision, recall, and F1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ZE7A0Au1Pg0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "baa9e243-c6f0-4287-c8bf-4d1fba79f60c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+----------+--------------------+--------------------+--------------------+\n",
            "|   Algorithm    | Accuracy |     Precision      |       Recall       |         F1         |\n",
            "+----------------+----------+--------------------+--------------------+--------------------+\n",
            "| MLP Classifier |  0.751   | 0.7514705690391223 | 0.7482445859801603 | 0.7480212785189385 |\n",
            "| Random Forest  |  0.809   | 0.8016443835270527 | 0.8060159063001743 | 0.8005314796665488 |\n",
            "|      k-NN      |  0.773   | 0.7764817768116947 | 0.7722676691083874 | 0.7650305741237794 |\n",
            "|  Naïve Bayes   |  0.583   | 0.6004354166274228 | 0.5856646244149746 | 0.5492472873074626 |\n",
            "+----------------+----------+--------------------+--------------------+--------------------+\n"
          ]
        }
      ],
      "source": [
        " fashion_train = pd.read_csv(\"/content/sample_data/fashion_train.csv\")\n",
        " fashion_test = pd.read_csv(\"/content/sample_data/fashion_test.csv\")\n",
        " X_train = fashion_train.drop(columns=\"y\")\n",
        " y_train = fashion_train[\"y\"]\n",
        " X_test = fashion_test.drop(columns=\"y\")\n",
        " y_test = fashion_test[\"y\"]\n",
        " selector = SelectKBest(chi2, k=400)\n",
        " X_train_selected = selector.fit_transform(X_train, y_train)\n",
        " X_test_selected = selector.transform(X_test)\n",
        " mlp_classifier = MLPClassifier(hidden_layer_sizes=(250, 100), activation='relu', solver='adam', max_iter=1000)\n",
        " rf_classifier = RandomForestClassifier()\n",
        " knn_classifier = KNeighborsClassifier()\n",
        " nb_classifier = GaussianNB()\n",
        " mlp_classifier.fit(X_train_selected, y_train)\n",
        " mlp_y_pred = mlp_classifier.predict(X_test_selected)\n",
        " mlp_accuracy = accuracy_score(y_test, mlp_y_pred)\n",
        " mlp_precision = precision_score(y_test, mlp_y_pred, average=\"macro\")\n",
        " mlp_recall = recall_score(y_test, mlp_y_pred, average=\"macro\")\n",
        " mlp_f1 = f1_score(y_test, mlp_y_pred, average=\"macro\")\n",
        " rf_classifier.fit(X_train_selected, y_train)\n",
        " rf_y_pred = rf_classifier.predict(X_test_selected)\n",
        " rf_accuracy = accuracy_score(y_test, rf_y_pred)\n",
        " rf_precision = precision_score(y_test, rf_y_pred, average=\"macro\")\n",
        " rf_recall = recall_score(y_test, rf_y_pred, average=\"macro\")\n",
        " rf_f1 = f1_score(y_test, rf_y_pred, average=\"macro\")\n",
        " knn_classifier.fit(X_train_selected, y_train)\n",
        " knn_y_pred = knn_classifier.predict(X_test_selected)\n",
        " knn_accuracy = accuracy_score(y_test, knn_y_pred)\n",
        " knn_precision = precision_score(y_test, knn_y_pred, average=\"macro\")\n",
        " knn_recall = recall_score(y_test, knn_y_pred, average=\"macro\")\n",
        " knn_f1 = f1_score(y_test, knn_y_pred, average=\"macro\")\n",
        " nb_classifier.fit(X_train_selected, y_train)\n",
        " nb_y_pred = nb_classifier.predict(X_test_selected)\n",
        " nb_accuracy = accuracy_score(y_test, nb_y_pred)\n",
        " nb_precision = precision_score(y_test, nb_y_pred, average=\"macro\")\n",
        " nb_recall = recall_score(y_test, nb_y_pred, average=\"macro\")\n",
        " nb_f1 = f1_score(y_test, nb_y_pred, average=\"macro\")\n",
        " table = PrettyTable([\"Algorithm\", \"Accuracy\", \"Precision\", \"Recall\", \"F1\"])\n",
        " table.add_row([\"MLP Classifier\", mlp_accuracy, mlp_precision, mlp_recall, mlp_f1])\n",
        " table.add_row([\"Random Forest\", rf_accuracy, rf_precision, rf_recall, rf_f1])\n",
        " table.add_row([\"k-NN\", knn_accuracy, knn_precision, knn_recall, knn_f1])\n",
        " table.add_row([\"Naïve Bayes\", nb_accuracy, nb_precision, nb_recall, nb_f1])\n",
        " print(table)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBSLD_k3Pk3X"
      },
      "source": [
        "#Task 3. With **breast cancer** dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1IZborjPzMH"
      },
      "source": [
        "*   3.1. Apply **GridSearchCV** to **MultilayperPerceptron** to find the best hyperparameters (the setting of hyperparameters chosen by students)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m-mbZEK0QZTv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "845d05b6-310a-4e04-e133-20e378bdd92f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Estimator:\n",
            "MLPClassifier(activation='tanh', hidden_layer_sizes=(100, 50), max_iter=2000)\n",
            "Best Hyperparameters:\n",
            "{'activation': 'tanh', 'hidden_layer_sizes': (100, 50), 'max_iter': 2000, 'solver': 'adam'}\n"
          ]
        }
      ],
      "source": [
        "#code\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "param_grid = {\n",
        "    'hidden_layer_sizes': [(100,), (100, 50), (50, 50)],\n",
        "    'activation': ['relu', 'tanh'],\n",
        "    'solver': ['adam', 'sgd'],\n",
        "    'max_iter': [1000, 2000]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(estimator=MLPClassifier(), param_grid=param_grid, n_jobs=-1, cv=3)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "best_estimator = grid_search.best_estimator_\n",
        "best_params = grid_search.best_params_\n",
        "\n",
        "print(\"Best Estimator:\")\n",
        "print(best_estimator)\n",
        "print(\"Best Hyperparameters:\")\n",
        "print(best_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H77rqX7sPv9v"
      },
      "source": [
        "*   3.2. Compare the **MultilayerPerceptron** using the best hyperparameters in 3.1) and other classification algorithms (i.e., Random forest, kNN, Naïve Bayes)  in termns of accuracy, precision, recall, and F1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pBU6vVH_QakV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8123a87c-706d-49d1-f54c-ee65e479da43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Algorithm  Accuracy  Precision    Recall  F1_Score\n",
            "0            MLP  0.964912   0.958904  0.985915  0.972222\n",
            "1  Random Forest  0.964912   0.958904  0.985915  0.972222\n",
            "2            kNN  0.956140   0.934211  1.000000  0.965986\n",
            "3    Naïve Bayes  0.973684   0.959459  1.000000  0.979310\n"
          ]
        }
      ],
      "source": [
        "#code\n",
        "best_mlp_params = {'hidden_layer_sizes': (100,), 'activation': 'relu', 'solver': 'adam', 'max_iter': 1000}\n",
        "mlp_classifier = MLPClassifier(**best_mlp_params)\n",
        "rf_classifier = RandomForestClassifier()\n",
        "knn_classifier = KNeighborsClassifier()\n",
        "nb_classifier = GaussianNB()\n",
        "\n",
        "mlp_classifier.fit(X_train, y_train)\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "knn_classifier.fit(X_train, y_train)\n",
        "nb_classifier.fit(X_train, y_train)\n",
        "\n",
        "mlp_y_pred = mlp_classifier.predict(X_test)\n",
        "rf_y_pred = rf_classifier.predict(X_test)\n",
        "knn_y_pred = knn_classifier.predict(X_test)\n",
        "nb_y_pred = nb_classifier.predict(X_test)\n",
        "\n",
        "mlp_accuracy = accuracy_score(y_test, mlp_y_pred)\n",
        "mlp_precision = precision_score(y_test, mlp_y_pred)\n",
        "mlp_recall = recall_score(y_test, mlp_y_pred)\n",
        "mlp_f1 = f1_score(y_test, mlp_y_pred)\n",
        "\n",
        "rf_accuracy = accuracy_score(y_test, rf_y_pred)\n",
        "rf_precision = precision_score(y_test, rf_y_pred)\n",
        "rf_recall = recall_score(y_test, rf_y_pred)\n",
        "rf_f1 = f1_score(y_test, rf_y_pred)\n",
        "\n",
        "knn_accuracy = accuracy_score(y_test, knn_y_pred)\n",
        "knn_precision = precision_score(y_test, knn_y_pred)\n",
        "knn_recall = recall_score(y_test, knn_y_pred)\n",
        "knn_f1 = f1_score(y_test, knn_y_pred)\n",
        "\n",
        "nb_accuracy = accuracy_score(y_test, nb_y_pred)\n",
        "nb_precision = precision_score(y_test, nb_y_pred)\n",
        "nb_recall = recall_score(y_test, nb_y_pred)\n",
        "nb_f1 = f1_score(y_test, nb_y_pred)\n",
        "\n",
        "results = pd.DataFrame({\n",
        "    'Algorithm': ['MLP', 'Random Forest', 'kNN', 'Naïve Bayes'],\n",
        "    'Accuracy': [mlp_accuracy, rf_accuracy, knn_accuracy, nb_accuracy],\n",
        "    'Precision': [mlp_precision, rf_precision, knn_precision, nb_precision],\n",
        "    'Recall': [mlp_recall, rf_recall, knn_recall, nb_recall],\n",
        "    'F1_Score': [mlp_f1, rf_f1, knn_f1, nb_f1]\n",
        "})\n",
        "\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JdCVnj_89Fl"
      },
      "source": [
        "#Task 4. With **mobile price classification** dataset\n",
        "\n",
        "\n",
        "*   4.1. Build your own Neural Network using **MultilayerPerceptron**  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ePpTY6Lk9X2V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f3d0493-b267-4543-c96d-f080d0bfbe2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+----------+--------------------+--------------------+--------------------+\n",
            "|   Algorithm    | Accuracy |     Precision      |       Recall       |         F1         |\n",
            "+----------------+----------+--------------------+--------------------+--------------------+\n",
            "| MLP Classifier |  0.5175  | 0.6978951229548137 | 0.5372924629718108 | 0.5045679104656468 |\n",
            "+----------------+----------+--------------------+--------------------+--------------------+\n"
          ]
        }
      ],
      "source": [
        "#code\n",
        "mobile = pd.read_csv(\"/content/sample_data/mobile.csv\")\n",
        "\n",
        "X = mobile.drop(columns=\"price_range\")\n",
        "y = mobile[\"price_range\"]\n",
        "\n",
        "selector = SelectKBest(chi2, k=10)\n",
        "X_selected = selector.fit_transform(X, y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)\n",
        "\n",
        "myMLP = MLPClassifier(max_iter=10000, hidden_layer_sizes=(200, 100, 20))\n",
        "myMLP.fit(X_train, y_train)\n",
        "\n",
        "y_pred = myMLP.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average=\"macro\")\n",
        "recall = recall_score(y_test, y_pred, average=\"macro\")\n",
        "f1 = f1_score(y_test, y_pred, average=\"macro\")\n",
        "\n",
        "table = PrettyTable([\"Algorithm\", \"Accuracy\", \"Precision\", \"Recall\", \"F1\"])\n",
        "table.add_row([\"MLP Classifier\", accuracy, precision, recall, f1])\n",
        "print(table)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqlFS6ic9ZCV"
      },
      "source": [
        "*   4.2. Apply **GridSearchCV** to **MultilayperPerceptron** to find the best hyperparameters (the setting of hyperparameters chosen by students)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OvW2yGUU9_ik",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61501200-576e-45c2-f3b4-cf27a469d5df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Estimator:\n",
            "MLPClassifier(activation='tanh', hidden_layer_sizes=(100, 50), max_iter=1000)\n",
            "Best Hyperparameters:\n",
            "{'activation': 'tanh', 'hidden_layer_sizes': (100, 50), 'max_iter': 1000, 'solver': 'adam'}\n",
            "Accuracy: 0.6575\n",
            "Precision: 0.652854568287577\n",
            "Recall: 0.6480953376333811\n",
            "F1 Score: 0.6492847275804168\n"
          ]
        }
      ],
      "source": [
        "#code\n",
        "import pandas as pd\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "mobile = pd.read_csv(\"/content/sample_data/mobile.csv\")\n",
        "\n",
        "X = mobile.drop(columns=\"price_range\")\n",
        "y = mobile[\"price_range\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "param_grid = {\n",
        "    'hidden_layer_sizes': [(100,), (100, 50), (50, 50)],\n",
        "    'activation': ['relu', 'tanh'],\n",
        "    'solver': ['adam', 'sgd'],\n",
        "    'max_iter': [1000, 2000]\n",
        "}\n",
        "\n",
        "mlp_classifier = MLPClassifier()\n",
        "\n",
        "grid_search = GridSearchCV(estimator=mlp_classifier, param_grid=param_grid, cv=3)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "best_estimator = grid_search.best_estimator_\n",
        "best_params = grid_search.best_params_\n",
        "\n",
        "print(\"Best Estimator:\")\n",
        "print(best_estimator)\n",
        "print(\"Best Hyperparameters:\")\n",
        "print(best_params)\n",
        "\n",
        "y_pred = best_estimator.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average=\"macro\")\n",
        "recall = recall_score(y_test, y_pred, average=\"macro\")\n",
        "f1 = f1_score(y_test, y_pred, average=\"macro\")\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ok7RGkea_b7n"
      },
      "source": [
        "#Finally,\n",
        "Save a copy in your Github. Remember renaming the notebook."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}