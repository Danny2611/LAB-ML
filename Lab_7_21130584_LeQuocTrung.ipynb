{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Danny2611/LAB-ML/blob/master/Lab_7_21130584_LeQuocTrung.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# This lab deals with **GridSearchCV** for tuning the hyper-parameters of an estimator and applying vectorization techniques to the **movie reviews dataset** for classification task.\n",
        "\n",
        "*   **Deadline: 23:59, 22/4/2024 (lớp TH thứ 3) || 29/4/2024 (lớp TH thứ 5)**\n",
        "\n"
      ],
      "metadata": {
        "id": "LMzehe0sy5wr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import libraries"
      ],
      "metadata": {
        "id": "H4nJmxp9zGX4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DoVWQ8AEyc-C"
      },
      "outputs": [],
      "source": [
        "# code\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 1. With **iris** dataset\n",
        "*  1.1. Apply **GridSearchCV** for **SVM** to find the best hyperparameters using the following param_grid.\n",
        "\n",
        "```\n",
        "param_grid = {'C': [0.1, 1, 10, 100, 1000],\n",
        "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
        "              'kernel': ['rbf','linear']}\n",
        "```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "x_dG9SA5OhGT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "param_grid = {'C': [0.1, 1, 10, 100, 1000],\n",
        "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
        "              'kernel': ['rbf', 'linear']}\n",
        "\n",
        "svm = SVC()\n",
        "\n",
        "\n",
        "grid_search = GridSearchCV(svm, param_grid, cv=5, verbose=2, n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best hyperparameters found:\")\n",
        "print(grid_search.best_params_)\n",
        "\n",
        "\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "62jExOZ952fF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a97a72e1-330b-4b98-98e1-0990ebcc0630"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
            "Best hyperparameters found:\n",
            "{'C': 1, 'gamma': 1, 'kernel': 'rbf'}\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        10\n",
            "           1       1.00      1.00      1.00         9\n",
            "           2       1.00      1.00      1.00        11\n",
            "\n",
            "    accuracy                           1.00        30\n",
            "   macro avg       1.00      1.00      1.00        30\n",
            "weighted avg       1.00      1.00      1.00        30\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*  1.2. Apply **GridSearchCV** for **kNN** to find the best hyperparameters using the following param_grid.\n",
        "\n",
        "```\n",
        "grid_params = { 'n_neighbors' : [5,7,9,11,13,15],\n",
        "               'weights' : ['uniform','distance'],\n",
        "               'metric' : ['minkowski','euclidean','manhattan']}\n",
        "```\n",
        "where\n",
        "\n",
        "    *  **n_neighbors**: Decide the best k based on the values we have computed earlier.\n",
        "    *  **weights**: Check whether adding weights to the data points is beneficial to the model or not. 'uniform' assigns no weight, while 'distance' weighs points by the inverse of their distances meaning nearer points will have more weight than the farther points.\n",
        "    *  **metric**: The distance metric to be used will calculating the similarity.\n"
      ],
      "metadata": {
        "id": "2g--8cng53sY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "grid_params = {'n_neighbors': [5, 7, 9, 11, 13, 15],\n",
        "               'weights': ['uniform', 'distance'],\n",
        "               'metric': ['minkowski', 'euclidean', 'manhattan']}\n",
        "\n",
        "knn = KNeighborsClassifier()\n",
        "\n",
        "\n",
        "grid_search_knn = GridSearchCV(knn, grid_params, cv=5, verbose=2, n_jobs=-1)\n",
        "grid_search_knn.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "print(\"Best hyperparameters found:\")\n",
        "print(grid_search_knn.best_params_)\n",
        "\n",
        "\n",
        "best_model_knn = grid_search_knn.best_estimator_\n",
        "y_pred_knn = best_model_knn.predict(X_test)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred_knn))\n"
      ],
      "metadata": {
        "id": "fX0_kItYPism",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49c85f23-f970-4bcd-906b-d9051c5d1ba7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
            "Best hyperparameters found:\n",
            "{'metric': 'minkowski', 'n_neighbors': 11, 'weights': 'uniform'}\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        10\n",
            "           1       1.00      1.00      1.00         9\n",
            "           2       1.00      1.00      1.00        11\n",
            "\n",
            "    accuracy                           1.00        30\n",
            "   macro avg       1.00      1.00      1.00        30\n",
            "weighted avg       1.00      1.00      1.00        30\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*  1.3. Apply **GridSearchCV** for **Random Forest** to find the best hyperparameters using the following param_grid.\n",
        "\n",
        "```\n",
        "param_grid = {\n",
        "    'n_estimators': [25, 50, 100, 150],\n",
        "    'max_features': ['sqrt', 'log2', None],\n",
        "    'max_depth': [3, 6, 9],\n",
        "    'max_leaf_nodes': [3, 6, 9],\n",
        "}\n",
        "```"
      ],
      "metadata": {
        "id": "3lQSOcjL_TIW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [25, 50, 100, 150],\n",
        "    'max_features': ['sqrt', 'log2', None],\n",
        "    'max_depth': [3, 6, 9],\n",
        "    'max_leaf_nodes': [3, 6, 9],\n",
        "}\n",
        "\n",
        "rf = RandomForestClassifier()\n",
        "\n",
        "\n",
        "grid_search = GridSearchCV(rf, param_grid, cv=5, verbose=2, n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best hyperparameters found:\")\n",
        "print(grid_search.best_params_)\n",
        "\n",
        "\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "OlyF9WpN_01p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa5a8e78-aef3-4739-fb40-c6d3972ee6a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
            "Best hyperparameters found:\n",
            "{'max_depth': 3, 'max_features': 'sqrt', 'max_leaf_nodes': 6, 'n_estimators': 25}\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        10\n",
            "           1       1.00      1.00      1.00         9\n",
            "           2       1.00      1.00      1.00        11\n",
            "\n",
            "    accuracy                           1.00        30\n",
            "   macro avg       1.00      1.00      1.00        30\n",
            "weighted avg       1.00      1.00      1.00        30\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   1.4 Compare the best obtained results from 1.1 to 1.3 (use PrettyTable to dispaly the results)"
      ],
      "metadata": {
        "id": "G3N7TD7s_3Kp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 2.\n",
        "For breast cancer dataset (https://tinyurl.com/3vme8hr3) which could be loaded from datasets in sklearn as follows:\n",
        "\n",
        "```\n",
        "#Import scikit-learn dataset library\n",
        "from sklearn import datasets\n",
        "\n",
        "#Load dataset\n",
        "cancer = datasets.load_breast_cancer()\n",
        "```\n",
        "\n",
        "*   Apply **GridSearchCV** to different classification algorithms such as **SVM, kNN, LogisticRegression, RandomForest**.\n",
        "*   Compare the results obtained by the best hyperparameters among classification algorithms."
      ],
      "metadata": {
        "id": "kNv07ARGzOUm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   2.1. Apply **GridSearchCV** to **SVM**\n"
      ],
      "metadata": {
        "id": "pnoVB8J4vV36"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# code\n",
        "\n",
        "\n",
        "cancer = datasets.load_breast_cancer()\n",
        "X, y = cancer.data, cancer.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "param_grid = {'C': [0.1, 1, 10],\n",
        "              'gamma': [1, 0.1, 0.01],\n",
        "              'kernel': ['rbf', 'linear']}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "svm = SVC()\n",
        "\n",
        "\n",
        "grid_search = GridSearchCV(svm, param_grid, cv=5, verbose=2, n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best hyperparameters found:\")\n",
        "print(grid_search.best_params_)\n",
        "\n",
        "\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n"
      ],
      "metadata": {
        "id": "-ZTSvsJdvYqI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be1b6432-6b83-45c3-cd63-93bccd3dff51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
            "Best hyperparameters found:\n",
            "{'C': 1, 'gamma': 1, 'kernel': 'linear'}\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.91      0.94        43\n",
            "           1       0.95      0.99      0.97        71\n",
            "\n",
            "    accuracy                           0.96       114\n",
            "   macro avg       0.96      0.95      0.95       114\n",
            "weighted avg       0.96      0.96      0.96       114\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   2.2. Apply **GridSearchCV** to **kNN**"
      ],
      "metadata": {
        "id": "ol1U_T_NvcqV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code\n",
        "\n",
        "\n",
        "\n",
        "cancer = datasets.load_breast_cancer()\n",
        "X, y = cancer.data, cancer.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "param_grid = {'n_neighbors': [5, 7, 9],\n",
        "              'weights': ['uniform', 'distance'],\n",
        "              'metric': ['euclidean', 'manhattan']}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "knn = KNeighborsClassifier()\n",
        "\n",
        "grid_search = GridSearchCV(knn, param_grid, cv=5, verbose=2, n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best hyperparameters found:\")\n",
        "print(grid_search.best_params_)\n",
        "\n",
        "\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n"
      ],
      "metadata": {
        "id": "kt71yrAoBwYE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76d9ec09-16b7-422e-8230-8667032cbad0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
            "Best hyperparameters found:\n",
            "{'metric': 'manhattan', 'n_neighbors': 7, 'weights': 'distance'}\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.86      0.91        43\n",
            "           1       0.92      0.99      0.95        71\n",
            "\n",
            "    accuracy                           0.94       114\n",
            "   macro avg       0.95      0.92      0.93       114\n",
            "weighted avg       0.94      0.94      0.94       114\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   2.3. Apply **GridSearchCV** to **LogisticRegression**"
      ],
      "metadata": {
        "id": "pPkAvse-BxNa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code\n",
        "#code\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "cancer = datasets.load_breast_cancer()\n",
        "X, y = cancer.data, cancer.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
        "              'penalty': ['l1', 'l2']}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "logistic_reg = LogisticRegression(max_iter=10000)\n",
        "\n",
        "grid_search = GridSearchCV(logistic_reg, param_grid, cv=5, verbose=2, n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best hyperparameters found:\")\n",
        "print(grid_search.best_params_)\n",
        "\n",
        "\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n"
      ],
      "metadata": {
        "id": "nyYjpHFbB1Ci",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66dc2b3c-93cc-4ee2-d2dd-d7815b326a98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
            "35 fits failed out of a total of 70.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "35 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan 0.92967033        nan 0.94065934        nan 0.95164835\n",
            "        nan 0.95384615        nan 0.96483516        nan 0.96483516\n",
            "        nan 0.96483516]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best hyperparameters found:\n",
            "{'C': 10, 'penalty': 'l2'}\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.91      0.94        43\n",
            "           1       0.95      0.99      0.97        71\n",
            "\n",
            "    accuracy                           0.96       114\n",
            "   macro avg       0.96      0.95      0.95       114\n",
            "weighted avg       0.96      0.96      0.96       114\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   2.4. Apply **GridSearchCV** to **RandomForest**"
      ],
      "metadata": {
        "id": "3NjSLo5jB1xY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#code\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "cancer = datasets.load_breast_cancer()\n",
        "X, y = cancer.data, cancer.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "param_grid = {'n_estimators': [50, 100, 150],\n",
        "              'max_features': ['sqrt', 'log2', None],\n",
        "              'max_depth': [3, 6, 9],\n",
        "              'max_leaf_nodes': [3, 6, 9]}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "random_forest = RandomForestClassifier()\n",
        "\n",
        "grid_search = GridSearchCV(random_forest, param_grid, cv=5, verbose=2, n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best hyperparameters found:\")\n",
        "print(grid_search.best_params_)\n",
        "\n",
        "\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n"
      ],
      "metadata": {
        "id": "nktGtM0PB7XB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0c40539-17e2-47ab-894c-b3ae14ca90dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
            "Best hyperparameters found:\n",
            "{'max_depth': 9, 'max_features': 'log2', 'max_leaf_nodes': 9, 'n_estimators': 50}\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.93      0.95        43\n",
            "           1       0.96      0.99      0.97        71\n",
            "\n",
            "    accuracy                           0.96       114\n",
            "   macro avg       0.97      0.96      0.96       114\n",
            "weighted avg       0.97      0.96      0.96       114\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   2.5. Compare the best obtained results among classification algorithms (use PrettyTable to dispaly the results)"
      ],
      "metadata": {
        "id": "NZJ3BSHpB9Dx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from prettytable import PrettyTable\n",
        "\n",
        "\n",
        "cancer = load_breast_cancer()\n",
        "X, y = cancer.data, cancer.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "results = []\n",
        "\n",
        "\n",
        "classifiers = {\n",
        "    'SVM': SVC(),\n",
        "    'kNN': KNeighborsClassifier(),\n",
        "    'Logistic Regression': LogisticRegression(max_iter=10000),\n",
        "    'Random Forest': RandomForestClassifier()\n",
        "}\n",
        "\n",
        "\n",
        "param_grids = {\n",
        "    'SVM': {'C': [0.001, 0.01, 0.1, 1, 10], 'kernel': ['linear', 'rbf']},\n",
        "    'kNN': {'n_neighbors': [3, 5, 7, 9]},\n",
        "    'Logistic Regression': {'C': [0.001, 0.01, 0.1, 1, 10], 'penalty': ['l1', 'l2']},\n",
        "    'Random Forest': {'n_estimators': [50, 100, 150], 'max_depth': [3, 6, None]}\n",
        "}\n",
        "\n",
        "\n",
        "for classifier_name, classifier in classifiers.items():\n",
        "    param_grid = param_grids[classifier_name]\n",
        "    grid_search = GridSearchCV(classifier, param_grid, cv=5, verbose=2, n_jobs=-1)\n",
        "    grid_search.fit(X_train, y_train)\n",
        "    best_params = grid_search.best_params_\n",
        "    best_model = grid_search.best_estimator_\n",
        "    y_pred = best_model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    results.append([classifier_name, best_params, accuracy])\n",
        "\n",
        "\n",
        "table = PrettyTable()\n",
        "table.field_names = ['Algorithm', 'Best Parameters', 'Accuracy']\n",
        "\n",
        "for result in results:\n",
        "    table.add_row(result)\n",
        "\n",
        "\n",
        "print(table)\n"
      ],
      "metadata": {
        "id": "8LS_IYfNCFEj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e8f4353-b009-41d9-a49e-1ee14184d6bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
            "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
            "25 fits failed out of a total of 50.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "25 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan 0.92967033        nan 0.94065934        nan 0.95164835\n",
            "        nan 0.95384615        nan 0.96483516]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
            "+---------------------+------------------------------------------+--------------------+\n",
            "|      Algorithm      |             Best Parameters              |      Accuracy      |\n",
            "+---------------------+------------------------------------------+--------------------+\n",
            "|         SVM         |       {'C': 1, 'kernel': 'linear'}       | 0.956140350877193  |\n",
            "|         kNN         |            {'n_neighbors': 9}            | 0.956140350877193  |\n",
            "| Logistic Regression |        {'C': 10, 'penalty': 'l2'}        | 0.956140350877193  |\n",
            "|    Random Forest    | {'max_depth': None, 'n_estimators': 100} | 0.9649122807017544 |\n",
            "+---------------------+------------------------------------------+--------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 3. With **mobile price classification** dataset\n",
        "* 3.1.  Apply **GridSearchCV** for **SVM, kNN, RandomForest** algorithms to find the best hyperparameters for each classification algorithm.\n",
        "* 3.2. Compare the best obtained results among classification algorithms (use PrettyTable to dispaly the results)"
      ],
      "metadata": {
        "id": "az26oYW1Yxuz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from prettytable import PrettyTable\n",
        "import pandas as pd\n",
        "\n",
        "def myGridSearchCV(X, y, classifier, param_grid):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "    grid_search = GridSearchCV(classifier, param_grid, cv=5, verbose=2, n_jobs=-1)\n",
        "    grid_search.fit(X_train, y_train)\n",
        "    best_params = grid_search.best_params_\n",
        "    best_model = grid_search.best_estimator_\n",
        "    y_pred = best_model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred, average='weighted')\n",
        "    recall = recall_score(y_test, y_pred, average='weighted')\n",
        "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "    return classifier.__class__.__name__, best_params, grid_search.best_score_, accuracy, precision, recall, f1\n",
        "\n",
        "mobile = pd.read_csv(\"/content/sample_data/mobile.csv\")\n",
        "mobile_sample = mobile.sample(frac=0.1, random_state=42)\n",
        "X = mobile_sample.drop(columns=['price_range'])\n",
        "y = mobile_sample['price_range']\n",
        "\n",
        "svm_param_grid = {'C': [0.1, 1, 10], 'gamma': [1, 0.1, 0.01, 0.001, 0.0001], 'kernel': ['rbf', 'linear']}\n",
        "knn_param_grid = {'n_neighbors': [5, 7, 9, 11], 'weights': ['uniform', 'distance'], 'metric': ['minkowski', 'euclidean']}\n",
        "rf_param_grid = {'n_estimators': [25, 50, 75], 'max_features': ['sqrt', 'log2'], 'max_depth': [3, 6, 9], 'max_leaf_nodes': [3, 6, 9]}\n",
        "\n",
        "classifiers = [\n",
        "    (SVC(), svm_param_grid),\n",
        "    (KNeighborsClassifier(), knn_param_grid),\n",
        "    (RandomForestClassifier(), rf_param_grid)\n",
        "]\n",
        "\n",
        "table = PrettyTable([\"Classifier\", \"Best_Score\", \"Accuracy\", \"Precision\", \"Recall\", \"F1_Score\"])\n",
        "\n",
        "for classifier, param_grid in classifiers:\n",
        "    algoName, best_params, best_score, accuracy, precision, recall, f1 = myGridSearchCV(X, y, classifier, param_grid)\n",
        "    print(f\"Classifier: {algoName}, Params: {best_params}\")\n",
        "    table.add_row([algoName, best_score, accuracy, precision, recall, f1])\n",
        "\n",
        "print(table)\n"
      ],
      "metadata": {
        "id": "_jsYpiNYWxXK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f54e758-ce05-42b8-ac2d-604e3ad6d567"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
            "Classifier: SVC, Params: {'C': 0.1, 'gamma': 1, 'kernel': 'linear'}\n",
            "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
            "Classifier: KNeighborsClassifier, Params: {'metric': 'minkowski', 'n_neighbors': 5, 'weights': 'uniform'}\n",
            "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
            "Classifier: RandomForestClassifier, Params: {'max_depth': 9, 'max_features': 'log2', 'max_leaf_nodes': 9, 'n_estimators': 75}\n",
            "+------------------------+------------+----------+--------------------+--------+--------------------+\n",
            "|       Classifier       | Best_Score | Accuracy |     Precision      | Recall |      F1_Score      |\n",
            "+------------------------+------------+----------+--------------------+--------+--------------------+\n",
            "|          SVC           |  0.94375   |   0.95   | 0.9576923076923076 |  0.95  | 0.9498106060606061 |\n",
            "|  KNeighborsClassifier  |   0.8875   |   0.85   | 0.8558712121212121 |  0.85  | 0.8507551487414187 |\n",
            "| RandomForestClassifier |  0.80625   |  0.775   | 0.7736596736596736 | 0.775  | 0.7716415830546264 |\n",
            "+------------------------+------------+----------+--------------------+--------+--------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 4.\n",
        "The dataset consists of **2000 user-created movie reviews** archived on the IMDb(Internet Movie Database). The reviews are equally partitioned into a positive set and a negative set (1000+1000). Each review consists of a plain text file (.txt) and a class label representing the overall user opinion.\n",
        "The class attribute has only two values: **pos** (positive) or **neg** (negative).\n"
      ],
      "metadata": {
        "id": "b52OPWPD2afi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   4.1 Importing additional libraries"
      ],
      "metadata": {
        "id": "lDcxOQRmDz_h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk, random\n",
        "nltk.download('movie_reviews')\n",
        "from nltk.corpus import movie_reviews\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "ZjyW06skDwvL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff4e7f78-1de2-44b9-a951-a83232969183"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   4.2. Movie reviews information"
      ],
      "metadata": {
        "id": "RJpsTIiyv-1h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code\n",
        "print(len(movie_reviews.fileids()))\n",
        "print(movie_reviews.categories())\n",
        "print(movie_reviews.words()[:100])\n",
        "print(movie_reviews.fileids()[:10])"
      ],
      "metadata": {
        "id": "5ZE7A0Au1Pg0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4701068-5f3e-4d3b-b5fd-df3b94ec925b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2000\n",
            "['neg', 'pos']\n",
            "['plot', ':', 'two', 'teen', 'couples', 'go', 'to', ...]\n",
            "['neg/cv000_29416.txt', 'neg/cv001_19502.txt', 'neg/cv002_17424.txt', 'neg/cv003_12683.txt', 'neg/cv004_12641.txt', 'neg/cv005_29357.txt', 'neg/cv006_17022.txt', 'neg/cv007_4992.txt', 'neg/cv008_29326.txt', 'neg/cv009_29417.txt']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   4.3. Create dataset from movie reviews"
      ],
      "metadata": {
        "id": "6pHmMpqMHS23"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documents = [(list(movie_reviews.words(fileid)), category)\n",
        "             for category in movie_reviews.categories()\n",
        "             for fileid in movie_reviews.fileids(category)]\n",
        "random.seed(123)\n",
        "random.shuffle(documents)"
      ],
      "metadata": {
        "id": "45aY6woMHSH5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Number of Reviews/Documents: {}'.format(len(documents)))\n",
        "print('Corpus Size (words): {}'.format(np.sum([len(d) for (d,l) in documents])))\n",
        "print('Sample Text of Doc 1:')\n",
        "print('-'*30)\n",
        "print(' '.join(documents[0][0][:50])) # first 50 words of the first document"
      ],
      "metadata": {
        "id": "NNke0Da5HqFa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8cde2aa-c420-41b3-e00f-4a3d3801196c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Reviews/Documents: 2000\n",
            "Corpus Size (words): 1583820\n",
            "Sample Text of Doc 1:\n",
            "------------------------------\n",
            "most movies seem to release a third movie just so it can be called a trilogy . rocky iii seems to kind of fit in that category , but manages to be slightly unique . the rocky formula of \" rocky loses fight / rocky trains / rocky wins fight\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_distr = Counter([label for (words, label) in documents])\n",
        "print(sentiment_distr)"
      ],
      "metadata": {
        "id": "vVFUEhnXHsGd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b04aadde-c521-4699-de84-751d76e864f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({'pos': 1000, 'neg': 1000})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   4.4. Train test split"
      ],
      "metadata": {
        "id": "jTXiEbMzHgVC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train, test = train_test_split(documents, test_size = 0.33, random_state=42)"
      ],
      "metadata": {
        "id": "v_-0gZZFHvJN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Sentiment Distrubtion for Train and Test\n",
        "print(Counter([label for (words, label) in train]))\n",
        "print(Counter([label for (words, label) in test]))"
      ],
      "metadata": {
        "id": "UUGlm5TGHvpV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ead69d12-4fc7-4704-c891-2662195c456c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({'neg': 674, 'pos': 666})\n",
            "Counter({'pos': 334, 'neg': 326})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = [' '.join(words) for (words, label) in train]\n",
        "X_test = [' '.join(words) for (words, label) in test]\n",
        "y_train = [label for (words, label) in train]\n",
        "y_test = [label for (words, label) in test]"
      ],
      "metadata": {
        "id": "l1ppl_0RHx1P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   4.5. Text Vectorization"
      ],
      "metadata": {
        "id": "7xUaXrjxH6Ee"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "\n",
        "tfidf_vec = TfidfVectorizer(min_df = 10, token_pattern = r'[a-zA-Z]+')\n",
        "X_train_bow = tfidf_vec.fit_transform(X_train) # fit train\n",
        "X_test_bow = tfidf_vec.transform(X_test) # transform test"
      ],
      "metadata": {
        "id": "fzwM0nsIH-8l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   4.6. Apply **SVM** with **GridSearchCV**"
      ],
      "metadata": {
        "id": "BP1vB3loIF28"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from prettytable import PrettyTable\n",
        "\n",
        "X_train_small, _, y_train_small, _ = train_test_split(X_train_bow, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'gamma': [1, 0.1, 0.01],\n",
        "    'kernel': ['rbf', 'linear']\n",
        "}\n",
        "\n",
        "svm_grid_search = GridSearchCV(\n",
        "    estimator=SVC(),\n",
        "    param_grid=param_grid,\n",
        "    scoring='accuracy',\n",
        "    refit=True,\n",
        "    cv=5,\n",
        "    return_train_score=True,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "svm_grid_search.fit(X_train_small, y_train_small)\n",
        "\n",
        "y_pred = svm_grid_search.predict(X_test_bow)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='macro')\n",
        "recall = recall_score(y_test, y_pred, average='macro')\n",
        "f1 = f1_score(y_test, y_pred, average='macro')\n",
        "\n",
        "best_params = svm_grid_search.best_params_\n",
        "best_score = svm_grid_search.best_score_\n",
        "\n",
        "print(\"Best parameters for SVM:\", best_params)\n",
        "\n",
        "table = PrettyTable([\"Classifier\", \"Best_Score\", \"Accuracy\", \"Precision\", \"Recall\", \"F1_Score\"])\n",
        "table.add_row([\"SVM with GridSearchCV\", best_score, accuracy, precision, recall, f1])\n",
        "print(table)\n"
      ],
      "metadata": {
        "id": "b3FHQqh1Hlrd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f064b53-852a-4be1-c92a-938ff8e6fba4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters for SVM: {'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}\n",
            "+-----------------------+--------------------+--------------------+-------------------+--------------------+--------------------+\n",
            "|       Classifier      |     Best_Score     |      Accuracy      |     Precision     |       Recall       |      F1_Score      |\n",
            "+-----------------------+--------------------+--------------------+-------------------+--------------------+--------------------+\n",
            "| SVM with GridSearchCV | 0.8563573136274722 | 0.8287878787878787 | 0.829531320539161 | 0.8284871973843724 | 0.8285797030829449 |\n",
            "+-----------------------+--------------------+--------------------+-------------------+--------------------+--------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   4.7. Apply **RandomForest** with **GridSearchCV**"
      ],
      "metadata": {
        "id": "N1Fy8jYBIdxi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from prettytable import PrettyTable\n",
        "\n",
        "X_train_small, _, y_train_small, _ = train_test_split(X_train_bow, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [25, 50, 100, 150],\n",
        "    'max_features': ['sqrt', 'log2', None],\n",
        "    'max_depth': [3, 6, 9],\n",
        "    'max_leaf_nodes': [3, 6, 9]\n",
        "}\n",
        "\n",
        "rf_grid_search = GridSearchCV(\n",
        "    estimator=RandomForestClassifier(),\n",
        "    param_grid=param_grid,\n",
        "    scoring='accuracy',\n",
        "    refit=True,\n",
        "    cv=5,\n",
        "    return_train_score=True,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "rf_grid_search.fit(X_train_small, y_train_small)\n",
        "\n",
        "y_pred = rf_grid_search.predict(X_test_bow)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='macro')\n",
        "recall = recall_score(y_test, y_pred, average='macro')\n",
        "f1 = f1_score(y_test, y_pred, average='macro')\n",
        "\n",
        "best_params = rf_grid_search.best_params_\n",
        "best_score = rf_grid_search.best_score_\n",
        "\n",
        "print(\"Best parameters for RandomForest:\", best_params)\n",
        "\n",
        "table = PrettyTable([\"Classifier\", \"Best_Score\", \"Accuracy\", \"Precision\", \"Recall\", \"F1_Score\"])\n",
        "table.add_row([\"RandomForest with GridSearchCV\", best_score, accuracy, precision, recall, f1])\n",
        "print(table)\n"
      ],
      "metadata": {
        "id": "Fyfw2R-gIhWl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c10598dd-f7eb-481b-b674-6ff58e79a1c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters for RandomForest: {'max_depth': 6, 'max_features': 'sqrt', 'max_leaf_nodes': 9, 'n_estimators': 150}\n",
            "+--------------------------------+--------------------+--------------------+-------------------+-------------------+--------------------+\n",
            "|           Classifier           |     Best_Score     |      Accuracy      |     Precision     |       Recall      |      F1_Score      |\n",
            "+--------------------------------+--------------------+--------------------+-------------------+-------------------+--------------------+\n",
            "| RandomForest with GridSearchCV | 0.8031514888067811 | 0.7712121212121212 | 0.773339455157637 | 0.770645824914588 | 0.7704908217054978 |\n",
            "+--------------------------------+--------------------+--------------------+-------------------+-------------------+--------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   4.8. Apply **kNN** with **GridSearchCV**"
      ],
      "metadata": {
        "id": "_btsVKjIIiLT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from prettytable import PrettyTable\n",
        "\n",
        "X_train_small, _, y_train_small, _ = train_test_split(X_train_bow, y_train, test_size=0.1, random_state=42)\n",
        "\n",
        "param_grid = {\n",
        "    'n_neighbors': [5, 7, 9, 11, 13, 15],\n",
        "    'weights': ['uniform', 'distance'],\n",
        "    'metric': ['minkowski', 'euclidean', 'manhattan']\n",
        "}\n",
        "\n",
        "knn_grid_search = GridSearchCV(\n",
        "    estimator=KNeighborsClassifier(),\n",
        "    param_grid=param_grid,\n",
        "    scoring='accuracy',\n",
        "    refit=True,\n",
        "    cv=5,\n",
        "    return_train_score=True,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "knn_grid_search.fit(X_train_small, y_train_small)\n",
        "\n",
        "y_pred = knn_grid_search.predict(X_test_bow)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='macro')\n",
        "recall = recall_score(y_test, y_pred, average='macro')\n",
        "f1 = f1_score(y_test, y_pred, average='macro')\n",
        "\n",
        "best_params = knn_grid_search.best_params_\n",
        "best_score = knn_grid_search.best_score_\n",
        "\n",
        "print(\"Best parameters for kNN:\", best_params)\n",
        "\n",
        "table = PrettyTable([\"Classifier\", \"Best_Score\", \"Accuracy\", \"Precision\", \"Recall\", \"F1_Score\"])\n",
        "table.add_row([\"kNN with GridSearchCV\", best_score, accuracy, precision, recall, f1])\n",
        "print(table)\n"
      ],
      "metadata": {
        "id": "IZmFu1ZQImhn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   4.9. Apply **LogisticRegression** with **GridSearchCV**"
      ],
      "metadata": {
        "id": "0Ix_HeVGIvDu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from prettytable import PrettyTable\n",
        "\n",
        "X_train_small, _, y_train_small, _ = train_test_split(X_train_bow, y_train, test_size=0.1, random_state=42)\n",
        "\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10, 100],\n",
        "    'solver': ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga']\n",
        "}\n",
        "\n",
        "# Create a GridSearchCV object\n",
        "log_reg_grid_search = GridSearchCV(\n",
        "    estimator=LogisticRegression(),\n",
        "    param_grid=param_grid,\n",
        "    scoring='accuracy',\n",
        "    refit=True,\n",
        "    cv=5,\n",
        "    return_train_score=True,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "log_reg_grid_search.fit(X_train_small, y_train_small)\n",
        "\n",
        "y_pred = log_reg_grid_search.predict(X_test_bow)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='macro')\n",
        "recall = recall_score(y_test, y_pred, average='macro')\n",
        "f1 = f1_score(y_test, y_pred, average='macro')\n",
        "\n",
        "best_params = log_reg_grid_search.best_params_\n",
        "best_score = log_reg_grid_search.best_score_\n",
        "\n",
        "print(\"Best parameters for Logistic Regression:\", best_params)\n",
        "\n",
        "table = PrettyTable([\"Classifier\", \"Best_Score\", \"Accuracy\", \"Precision\", \"Recall\", \"F1_Score\"])\n",
        "table.add_row([\"Logistic Regression with GridSearchCV\", best_score, accuracy, precision, recall, f1])\n",
        "print(table)\n"
      ],
      "metadata": {
        "id": "sTd3alCMIr-i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d6c32d9-171c-4b3a-cebd-7c5514f2ba68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters for Logistic Regression: {'C': 100, 'solver': 'sag'}\n",
            "+---------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|               Classifier              |     Best_Score     |      Accuracy      |     Precision      |       Recall       |      F1_Score      |\n",
            "+---------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "| Logistic Regression with GridSearchCV | 0.8582284558142727 | 0.8212121212121212 | 0.8224770134042317 | 0.8208184857279306 | 0.8208897556667648 |\n",
            "+---------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   4.10. Compare the best obtained results among classification algorithms (use PrettyTable to dispaly the results)"
      ],
      "metadata": {
        "id": "nhYF2y6eI058"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from prettytable import PrettyTable\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "table = PrettyTable([\"Classifier\", \"Best_Score\", \"Accuracy\", \"Precision\", \"Recall\", \"F1_Score\"])\n",
        "\n",
        "table.add_row([\"SVM\", svm_best_score, svm_accuracy, svm_precision, svm_recall, svm_f1])\n",
        "table.add_row([\"kNN\", knn_best_score, knn_accuracy, knn_precision, knn_recall, knn_f1])\n",
        "table.add_row([\"Logistic Regression\", log_reg_best_score, log_reg_accuracy, log_reg_precision, log_reg_recall, log_reg_f1])\n",
        "\n",
        "print(table)\n"
      ],
      "metadata": {
        "id": "AbvURu4ZvWnZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Finally,\n",
        "Save a copy in your Github. Remember renaming the notebook."
      ],
      "metadata": {
        "id": "Ok7RGkea_b7n"
      }
    }
  ]
}